{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンテンツ\n",
    "1. LoRAとはなにか\n",
    "2. LoRAの主要なハイパーパラメータ\n",
    "3. LoRAはなぜ有効なのか\n",
    "4. おまけ：QLoRAとは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRAとはなにか\n",
    "Low Rank Adaptationの略(Rankは線形代数でよく出てくる行列の階数的なアレ)\n",
    "ディープラーニングモデルで学習可能なパラメータ数を限定して計算量を削減するテクニック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通常のパラメータ学習\n",
    "![](../images/visual_gpt2.png)\n",
    "- たとえば上図はGPT系モデルの概要である\n",
    "- そのうちの一つの層、Feed Forward層は線形変換\n",
    "\n",
    "![](../images/dn.png)\n",
    "- FeedForward層(リニア層)の場合、パラメータ数はシンプルに`入力ノード数×出力ノード数`になる。上記の例では最初のリニア層のパラメータ数は12個。\n",
    "\n",
    "- LLMの入力は１つのトークンを埋め込みベクトルとして表現したもの、出力は同じ次元数のベクトル\n",
    "- つまり埋め込みベクトルが1600次元なら、パラメータは(1600,1600)行列Wで表現できる\n",
    "- 学習時はこのパラメータがすべて(256,000個！)少しずつ変化していく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA導入時のパラメータ学習\n",
    "- この(1600,1600)行列`W`をと(16,1600)行列`A`と(1600,16)行列`B`の積で表したら、学習パラメータ数が51,200個(1600×16×2)まで削減できますやん、という発想。\n",
    "\n",
    "![](../images/lora.PNG)\n",
    "\n",
    "この図だと`d=1600`、`r=16`\n",
    "- 左側の青い1層のパラメータは学習させない。固定する。\n",
    "- 右側の赤い2層(これをAdapterという)をかっぽりとはめこみ、学習を担当させる。\n",
    "$h = (W + \\Delta W) x$\n",
    "- 行列`A`、`B`ともに高々ランク`r`なのでもとの$\\delta W$も高々ランク`r`($r << d$)\n",
    "- これがLow rank adaptationの由来(低ランク行列をはめ込む)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRAの主要なハイパーパラメータ\n",
    "## 1.$ｒ$\n",
    "- 最重要ハイパーパラメータ\n",
    "- ただどうやって決めればいいのかわからない。誰も教えてくれない。\n",
    "- peftライブラリだとデフォルト値が`8`になっており、そんな小さくして大丈夫なのかと勝手に思っている\n",
    "\n",
    "## 2. $\\alpha$\n",
    "- 通常の学習における学習率$\\eta$に相当するハイパーパラメータ\n",
    "- 学習率とは、勾配$\\delta$(修正する方向)を求めた後に、どれだけ進むかを表す指標\n",
    "- LoRAにおいては通常の学習率を適用して$\\delta W$行列を更新した後に、さらにそれをスケーリングするようになっている(たぶん)。実際には$\\delta W$は$\\frac{\\alpha}{r}$倍される(つまりrが大きいときはスケーリングファクターはそのぶん小さくなるよう調整される)\n",
    "- peftではデフォルト値は8なので、スケーリングファクターは1になる。つまりスケールしない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# なぜLoRAは有効なテクニックなのか\n",
    "- LoRAでは実際に$W$の勾配行列$\\Delta W$を計算する代わりに\n",
    "それよりも低ランクの$\\Delta W'$で近似している。この近似に妥当性があるときにかぎりLoRAは有効であるといえる\n",
    "\n",
    "- 結論としてはLLMのリニア層では、ひとつだけをとってみれば1600次元もの変換は起こっておらず、それよりもはるかに小さい次元での変換のみが起こっていることが多いらしい。そのためLoRAは有効であるといえる\n",
    "\n",
    "- 以下では低ランク行列近似を実際のコードで示す。ポイントは行列の特異値分解である"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行列Aの階数: 5\n",
      "行列Aの階数: 5\n",
      "行列dWの階数: 5\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 行列の階数チェック\n",
    "def check_the_rank_of_BA():\n",
    "    A = np.random.rand(5, 20)\n",
    "    B = np.random.rand(20, 5)\n",
    "    W_delta = B @ A\n",
    "    print(\"行列Aの階数:\", np.linalg.matrix_rank(W_delta))\n",
    "    print(\"行列Aの階数:\", np.linalg.matrix_rank(W_delta))\n",
    "    print(\"行列dWの階数:\", np.linalg.matrix_rank(W_delta))\n",
    "\n",
    "check_the_rank_of_BA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20)\n",
      "(15,)\n",
      "(15, 15)\n"
     ]
    }
   ],
   "source": [
    "# 特異値分解\n",
    "# すべての行列はU(直行行列) * S(対角行列) * V(直行行列)に分解できる\n",
    "def svd_test():\n",
    "    w = np.random.rand(20, 20)\n",
    "    u, s, vh = np.linalg.svd(w)\n",
    "    print(u.shape)\n",
    "    print(s.shape)\n",
    "    print(vh.shape)\n",
    "\n",
    "svd_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行列の低ランク行列近似\n",
    "def low_rank_matrix_approx(n, rank):\n",
    "    # 行列の生成\n",
    "    w_original = np.random.rand(n, n)\n",
    "    # 特異値分解\n",
    "    u, s, vh = np.linalg.svd(w_original)\n",
    "    s = np.diag(s)\n",
    "    # 低ランク行列近似\n",
    "    ur = u[:, :rank]\n",
    "    sr = s[:rank, :rank]\n",
    "    vhr = vh[:rank, :]\n",
    "    w_low_rank = ur @ sr @ vhr\n",
    "    # 誤差の計算\n",
    "    error = np.linalg.norm(w - w_low_rank)\n",
    "    print(\"w: \", w_original)\n",
    "    print(\"w_low_rank: \", w_low_rank)\n",
    "    print(\"誤差:\", error)\n",
    "\n",
    "low_rank_matrix_approx(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def adapt_low_rank_matrix_to_image(path):\n",
    "    im = Image.open(path).convert('L')\n",
    "    pix = np.array(im)\n",
    "    print(pix.shape)\n",
    "    u, s, vh = np.linalg.svd(pix)\n",
    "    ranks = [1, 5, 10, 20, 50, 100, 200, 300]\n",
    "    for rank in ranks:\n",
    "        ur = u[:, :rank]\n",
    "        sr = np.diag(s[:rank])\n",
    "        vhr = vh[:rank, :]\n",
    "        pix_after = ur @ sr @ vhr\n",
    "        res = Image.fromarray(pix_after)\n",
    "        print(\"rank:\", rank)\n",
    "        res.show()\n",
    "\n",
    "adapt_low_rank_matrix_to_image(\"../images/example_for_Lora.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考文献・URL\n",
    "- [LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2106.09685.pdf)\n",
    "- [Understanding LoRA and QLoRA — The Powerhouses of Efficient Finetuning in Large Language Models](https://medium.com/@gitlostmurali/understanding-lora-and-qlora-the-powerhouses-of-efficient-finetuning-in-large-language-models-7ac1adf6c0cf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
