# エコーキャンセリング機能とは

スピーカーから出た音声をマイクロフォンが拾わないようにする技術

## 物理的解決

- マイクロフォンとスピーカーの距離を極力離す
- イヤフォンやヘッドフォンで出力先を制限する

## ハードウェア的解決

- 市販スピーカーフォン(スピーカー＋マイクロフォン)には DSP(digital signal processing)回路が内蔵されているものも多い
  - [神ブログ見つけた](https://note.com/nagataniyoshiki/n/nebd39326d046)
  - [神ブログ見つけた その2](https://note.com/nagataniyoshiki/n/nde3dd774cb8c)
- スマートフォンにも内蔵されているっぽい
- PC(特にノートパソコン)はこの機能がない、よわい

## ソフトウェア的解決

- OS(しらん)
- ブラウザ
- そのほかアプリケーション(しらん)

## ブラウザのエコーキャンセリング

- webRTC(映像のリアルタイム配信用のプロトコル?)がエコーキャンセリング機能を要件に定めているらしく、ブラウザでその機能を提供している。
- [メディアキャプチャとストリーム API](https://developer.mozilla.org/ja/docs/Web/API/Media_Capture_and_Streams_API)は webRTC に関連した API
- この API 経由でマイクと接続すると、わりと高機能なエコーキャンセリング機能が使える

# これを踏まえてブラウザ JS で書き直したが、いろいろ壁

- ファイルシステムにアクセスできない
  - いちいち API key を html 経由で入力したり、サーバーから取得させたりする必要あり
- マルチスレッドでいきたいときは worker というバックグラウンドスレッドが必要だが、これも使えるAPIに制約あり
- ウェブサービス側の API たたくのも制限あることが多い
  - くわしくわからないが CORR がどうとか same origin がどうとかよく怒られる
- node.js にくらべて各種 SDK の充実度も低い
  - セキュリティ的におすすめしないとか言われる
- ブラウザだから web speech API 無料で使えるじゃんやった！
  - からの、web speech api 経由で音声取得すると、上述のエコーキャンセリング機能が使えない(融通がきかない！) 
  - [Echo cancellation? #124](https://github.com/JamesBrill/react-speech-recognition/issues/124)
    　-「web speech API は音声で html を操作したい」みたいな発想なので、対話システムは想定外なのかも(推測)


# それらを経てできあがった
## 課題
- 発話中断機能(ユーザーが中断して発話したときに自分の発話を一旦ストップできるか)
  - 不要。会話はどんどん流れていくもの。いちどLLMで生成したレスポンスを後のために保持しておくのは現実的ではない
- 発話上書き機能(ユーザーが中断して発話したときに自分の発話を上書きできるか)
  - VAD(voice activity detection)で解決した
    - ユーザーが発話したのを最初の段階で検知し、abortシグナルを出す。ハンドラで発話ストップ。
    - VADがOFFになるまで、次から次へ流れてくる出力音声もすべて捨て去る
- 発話補強機能(ユーザーが長い間断続的に話しているときにあいづちをうてるか)
  - gemini APIはユーザー発話に「うんこ」とか「おっぱい」とか含めるとエラー返してくる、これの処理。

## さらなる課題
- 一つの発話の長さをコントロールできない
　- プロンプトで短文で返せと言ってもしゃべりすぎる。
　- 傾聴を表現できない
　- あるいは傾聴スタイルと漫才スタイルなど、スタイルでコードをけっこう書きかえる必要ある
- 発話の中でシステムプロンプトの内容を漏らしちゃう(gemini)
- アルファベットの単語をアルファベットで読んじゃう
　- これ日本語TTS機能特有の問題。テクノロジー系の話題やるなら追加学習マスト。)

# 結論

ブラウザはびびるほど高機能だが、制約も多い！諸刃！


---
添削要請プロンプト
```
上記のメモ書きを添削してください。
- 事実に反する項目があれば指摘して修正してください。
- 重要な論点が抜けていれば追加してください。

htmlからマークダウン形式の文字列をコピー＆ペーストしたいため、raw文字列を出力してください。
```

# 以下ChatGPTによる添削
以下のように添削・修正しました。修正点と理由は、内容の正確性、読みやすさ、細かな技術的補足を加えています。重要な論点については、主に「エコーキャンセリングの各解決法とその課題」、「ブラウザ特有の制約と対応法」、「開発課題の具体例」を中心に整理しました。

# エコーキャンセリング機能とは

スピーカーから出た音声がマイクロフォンに拾われないようにする技術。オンライン会話やビデオ通話で必要とされ、ユーザーの音声のみを正確に伝えるために活用される。

## 物理的解決

- マイクロフォンとスピーカーの距離を離すことでエコーの干渉を軽減。
- イヤフォンやヘッドフォンを使用して出力を耳元に限定することで、エコー発生を防ぐ。

## ハードウェア的解決

- 市販のスピーカーフォンには、DSP \(Digital Signal Processing\) 回路が内蔵されているものが多く、これによりエコーキャンセリングが行われる。
  - [参考ブログ](https://note.com/nagataniyoshiki/n/nebd39326d046)
  - [参考ブログ その2](https://note.com/nagataniyoshiki/n/nde3dd774cb8c)
- スマートフォンにはエコーキャンセリング用のDSPが内蔵されている機種が多い。
- 一部のPC（特にノートPC）にはエコーキャンセリング機能が内蔵されているが、性能はスマートフォンなどに比べて弱い場合が多い。

## ソフトウェア的解決

- エコーキャンセリング機能は、OS、ブラウザ、各種アプリケーションにより異なる実装がある。
- 主に音声通信を伴うアプリケーションや通話アプリで対応しているが、品質や互換性に差がある。

## ブラウザのエコーキャンセリング

- WebRTC（リアルタイム通信のためのプロトコル）にはエコーキャンセリングが要件に含まれており、ブラウザもこの機能を提供している。
- [メディアキャプチャとストリーム API](https://developer.mozilla.org/ja/docs/Web/API/Media_Capture_and_Streams_API)は WebRTC に関連するAPIで、マイクとの接続を通じて高機能なエコーキャンセリングを利用できる。

# JavaScriptによるブラウザ上での実装における課題

- **ファイルシステムにアクセスできない**  
  - APIキーはHTML経由で入力するか、サーバーから取得する必要があり、手間がかかる。
  
- **マルチスレッド処理**  
  - Worker（バックグラウンドスレッド）を使いたい場合、制約があり、特定のAPIが利用できないことがある。

- **ウェブサービスAPIの制限**  
  - サーバー間でのリクエストはCOR (Cross-Origin Resource)制限により、同一オリジンポリシーなどの制約に注意が必要。

- **SDKのサポート不足**  
  - Node.jsと比べて、ブラウザはセキュリティ制約のため対応していないSDKが多く、利便性に劣ることがある。

- **Web Speech API の制限**  
  - Web Speech API は無料で使えるものの、エコーキャンセリング機能の柔軟性が低く、音声認識中のエコー制御に限界がある。
  - 例えば、[Echo cancellation? #124](https://github.com/JamesBrill/react-speech-recognition/issues/124) ではWeb Speech APIがHTML操作を目的としており、対話システムとしての利用は想定外である可能性が示唆されている。

# 現状の実装と課題

## 実装した課題解決機能

- **発話中断機能**  
  - ユーザーの発話でシステムの発話を一時停止する必要はない。会話は流れていくものであり、LLMで生成されたレスポンスを保持して再利用するのは現実的でないため。

- **発話上書き機能**  
  - Voice Activity Detection (VAD) で解決。ユーザーの発話開始を検知してシステム側がabortシグナルを出し、発話を停止する。
  - VADがOFFになるまでシステムの発話を無視する処理も組み込んでいる。

- **発話補強機能**  
  - ユーザーが断続的に長話する際に適切な応答を返すようにした。
  - Gemini APIは不適切な表現（「うんこ」「おっぱい」など）を含む発話にエラーを返すため、フィルタリング処理を実装している。

## さらなる課題

- **発話長のコントロール**  
  - プロンプトで短文指定しても、生成される発話が長くなる傾向があるため、会話スタイルごとにコードの書き換えが必要。

- **システムプロンプト漏洩問題**  
  - 発話中にシステムプロンプトの内容が漏れることがあり、セキュリティとプライバシー面の対応が求められる。

- **アルファベット読み上げ**  
  - 日本語TTSではアルファベット単語が逐文字読みされる問題があるため、追加学習が必要。

# 結論

ブラウザは高機能で、WebRTCやエコーキャンセリングなど強力なツールを提供しているが、制約が多いため、実装にはさまざまな工夫と調整が必要。
